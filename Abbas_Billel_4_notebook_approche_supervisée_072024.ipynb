{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations standards\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# Importations des bibliothèques scientifiques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importations des bibliothèques de scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score, jaccard_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Importations des modèles d'autres bibliothèques\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Importations liées à la gestion des jobs\n",
    "import joblib\n",
    "from joblib import parallel_backend, dump, Parallel, delayed\n",
    "\n",
    "# Ignorer les avertissements spécifiques de sklearn\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importations des fonctions personnalisées\n",
    "import utils.utils_supervised as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données nettoyées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la partie supervisée, je vais utiliser les données d'entraînement pour trouver le meilleur modèle. Ensuite, je ferai la prédiction sur les données de test. Donc, je vais charger les données d'entraînement et de test :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les données Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>combined_title_body</th>\n",
       "      <th>split_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19245853</td>\n",
       "      <td>xcode iphone simulator look iphone</td>\n",
       "      <td>question device appearance iphone simulator xc...</td>\n",
       "      <td>xcode iphone simulator look iphone question de...</td>\n",
       "      <td>['ios', 'iphone', 'xcode', 'ios', 'simulator',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55921515</td>\n",
       "      <td>building dockerfile aptget update jailing proc...</td>\n",
       "      <td>docker host ubuntu docker snap dockerfile comm...</td>\n",
       "      <td>building dockerfile aptget update jailing proc...</td>\n",
       "      <td>['docker', 'ubuntu', 'nginx', 'dockerfile', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72575793</td>\n",
       "      <td>aadsts9002326 crossorigin token redemption isi...</td>\n",
       "      <td>send cross origin request access token react s...</td>\n",
       "      <td>aadsts9002326 crossorigin token redemption isi...</td>\n",
       "      <td>['javascript', 'reactjs', 'webpack', 'axios', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11489824</td>\n",
       "      <td>choose tesseract opencv</td>\n",
       "      <td>tesseract opencv look tesseract ocr engine ope...</td>\n",
       "      <td>choose tesseract opencv tesseract opencv look ...</td>\n",
       "      <td>['python', 'opencv', 'computer', 'vision', 'oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3489041</td>\n",
       "      <td>mysqlerror key max key length byte</td>\n",
       "      <td>cause database</td>\n",
       "      <td>mysqlerror key max key length byte cause database</td>\n",
       "      <td>['mysql', 'sql', 'ruby', 'on', 'rails', 'index...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                      cleaned_title  \\\n",
       "0  19245853                 xcode iphone simulator look iphone   \n",
       "1  55921515  building dockerfile aptget update jailing proc...   \n",
       "2  72575793  aadsts9002326 crossorigin token redemption isi...   \n",
       "3  11489824                            choose tesseract opencv   \n",
       "4   3489041                 mysqlerror key max key length byte   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  question device appearance iphone simulator xc...   \n",
       "1  docker host ubuntu docker snap dockerfile comm...   \n",
       "2  send cross origin request access token react s...   \n",
       "3  tesseract opencv look tesseract ocr engine ope...   \n",
       "4                                     cause database   \n",
       "\n",
       "                                 combined_title_body  \\\n",
       "0  xcode iphone simulator look iphone question de...   \n",
       "1  building dockerfile aptget update jailing proc...   \n",
       "2  aadsts9002326 crossorigin token redemption isi...   \n",
       "3  choose tesseract opencv tesseract opencv look ...   \n",
       "4  mysqlerror key max key length byte cause database   \n",
       "\n",
       "                                          split_tags  \n",
       "0  ['ios', 'iphone', 'xcode', 'ios', 'simulator',...  \n",
       "1  ['docker', 'ubuntu', 'nginx', 'dockerfile', 'a...  \n",
       "2  ['javascript', 'reactjs', 'webpack', 'axios', ...  \n",
       "3  ['python', 'opencv', 'computer', 'vision', 'oc...  \n",
       "4  ['mysql', 'sql', 'ruby', 'on', 'rails', 'index...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39881, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/stack_overflow_data_cleaned_train.csv\")\n",
    "display(train_df.head())\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les données Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>combined_title_body</th>\n",
       "      <th>split_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32177764</td>\n",
       "      <td>weight_decay meta parameter caffe</td>\n",
       "      <td>bvlccaffe git training meta parameter meta par...</td>\n",
       "      <td>weight_decay meta parameter caffe bvlccaffe gi...</td>\n",
       "      <td>['machine', 'learning', 'neural', 'network', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35870760</td>\n",
       "      <td>pyspark dataframe sqllike clause</td>\n",
       "      <td>filter pyspark dataframe sqllike clause tuple ...</td>\n",
       "      <td>pyspark dataframe sqllike clause filter pyspar...</td>\n",
       "      <td>['python', 'sql', 'apache', 'spark', 'datafram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10679214</td>\n",
       "      <td>set contenttype header httpclient request</td>\n",
       "      <td>set header object api allows header try throw ...</td>\n",
       "      <td>set contenttype header httpclient request set ...</td>\n",
       "      <td>['c#', 'aspnet', 'rest', 'content', 'type', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22157596</td>\n",
       "      <td>aspnet web api operationcanceledexception brow...</td>\n",
       "      <td>user load page ajax request hit aspnet web api...</td>\n",
       "      <td>aspnet web api operationcanceledexception brow...</td>\n",
       "      <td>['aspnet', 'iis', 'aspnet', 'web', 'api', 'tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6100573</td>\n",
       "      <td>draw line object</td>\n",
       "      <td>line control window form draw line line</td>\n",
       "      <td>draw line object line control window form draw...</td>\n",
       "      <td>['c#', 'winforms', 'user', 'interface', 'drawi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                      cleaned_title  \\\n",
       "0  32177764                  weight_decay meta parameter caffe   \n",
       "1  35870760                   pyspark dataframe sqllike clause   \n",
       "2  10679214          set contenttype header httpclient request   \n",
       "3  22157596  aspnet web api operationcanceledexception brow...   \n",
       "4   6100573                                   draw line object   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  bvlccaffe git training meta parameter meta par...   \n",
       "1  filter pyspark dataframe sqllike clause tuple ...   \n",
       "2  set header object api allows header try throw ...   \n",
       "3  user load page ajax request hit aspnet web api...   \n",
       "4            line control window form draw line line   \n",
       "\n",
       "                                 combined_title_body  \\\n",
       "0  weight_decay meta parameter caffe bvlccaffe gi...   \n",
       "1  pyspark dataframe sqllike clause filter pyspar...   \n",
       "2  set contenttype header httpclient request set ...   \n",
       "3  aspnet web api operationcanceledexception brow...   \n",
       "4  draw line object line control window form draw...   \n",
       "\n",
       "                                          split_tags  \n",
       "0  ['machine', 'learning', 'neural', 'network', '...  \n",
       "1  ['python', 'sql', 'apache', 'spark', 'datafram...  \n",
       "2  ['c#', 'aspnet', 'rest', 'content', 'type', 'd...  \n",
       "3  ['aspnet', 'iis', 'aspnet', 'web', 'api', 'tas...  \n",
       "4  ['c#', 'winforms', 'user', 'interface', 'drawi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9977, 5)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/stack_overflow_data_cleaned_test.csv\")\n",
    "display(test_df.head())\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prétraitement des données de la colonne `train_df['split_tags']` pour construire la variable cible `y` :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors du téléchargement des datasets test_df et train_df, le type de la variable de la colonne `split_tags` avait changé, donc il fallait les remettre au bon format :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les tags de chaînes de caractères en listes\n",
    "train_df['split_tags'] = train_df['split_tags'].apply(ast.literal_eval)\n",
    "test_df['split_tags'] = test_df['split_tags'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>combined_title_body</th>\n",
       "      <th>split_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19245853</td>\n",
       "      <td>xcode iphone simulator look iphone</td>\n",
       "      <td>question device appearance iphone simulator xc...</td>\n",
       "      <td>xcode iphone simulator look iphone question de...</td>\n",
       "      <td>[ios, iphone, xcode, ios, simulator, instruments]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55921515</td>\n",
       "      <td>building dockerfile aptget update jailing proc...</td>\n",
       "      <td>docker host ubuntu docker snap dockerfile comm...</td>\n",
       "      <td>building dockerfile aptget update jailing proc...</td>\n",
       "      <td>[docker, ubuntu, nginx, dockerfile, apt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72575793</td>\n",
       "      <td>aadsts9002326 crossorigin token redemption isi...</td>\n",
       "      <td>send cross origin request access token react s...</td>\n",
       "      <td>aadsts9002326 crossorigin token redemption isi...</td>\n",
       "      <td>[javascript, reactjs, webpack, axios, umijs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11489824</td>\n",
       "      <td>choose tesseract opencv</td>\n",
       "      <td>tesseract opencv look tesseract ocr engine ope...</td>\n",
       "      <td>choose tesseract opencv tesseract opencv look ...</td>\n",
       "      <td>[python, opencv, computer, vision, ocr, tesser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3489041</td>\n",
       "      <td>mysqlerror key max key length byte</td>\n",
       "      <td>cause database</td>\n",
       "      <td>mysqlerror key max key length byte cause database</td>\n",
       "      <td>[mysql, sql, ruby, on, rails, indexing, mysql,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                      cleaned_title  \\\n",
       "0  19245853                 xcode iphone simulator look iphone   \n",
       "1  55921515  building dockerfile aptget update jailing proc...   \n",
       "2  72575793  aadsts9002326 crossorigin token redemption isi...   \n",
       "3  11489824                            choose tesseract opencv   \n",
       "4   3489041                 mysqlerror key max key length byte   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  question device appearance iphone simulator xc...   \n",
       "1  docker host ubuntu docker snap dockerfile comm...   \n",
       "2  send cross origin request access token react s...   \n",
       "3  tesseract opencv look tesseract ocr engine ope...   \n",
       "4                                     cause database   \n",
       "\n",
       "                                 combined_title_body  \\\n",
       "0  xcode iphone simulator look iphone question de...   \n",
       "1  building dockerfile aptget update jailing proc...   \n",
       "2  aadsts9002326 crossorigin token redemption isi...   \n",
       "3  choose tesseract opencv tesseract opencv look ...   \n",
       "4  mysqlerror key max key length byte cause database   \n",
       "\n",
       "                                          split_tags  \n",
       "0  [ios, iphone, xcode, ios, simulator, instruments]  \n",
       "1           [docker, ubuntu, nginx, dockerfile, apt]  \n",
       "2       [javascript, reactjs, webpack, axios, umijs]  \n",
       "3  [python, opencv, computer, vision, ocr, tesser...  \n",
       "4  [mysql, sql, ruby, on, rails, indexing, mysql,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trier les mots par fréquence et sélectionner les 500 plus fréquents dans le corpus `train_df['split_tags']`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour optimiser l'entraînement des modèles supervisés, nous devons limiter le nombre de tags utilisés. Dans cette partie, nous allons identifier et sélectionner les 500 tags les plus fréquents du corpus, basés sur la colonne train_df['split_tags']. Cette approche simplifiera le modèle et améliorera potentiellement sa performance. Ensuite, nous filtrerons les documents pour ne conserver que ceux associés à ces 500 tags principaux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fréquence de chaque tag dans le corpus :\n",
      "\n",
      " python        6988\n",
      "java          6426\n",
      "javascript    5298\n",
      "android       5258\n",
      "c#            4999\n",
      "              ... \n",
      "mixer            1\n",
      "heapster         1\n",
      "cov              1\n",
      "esxi             1\n",
      "slidify          1\n",
      "Length: 9958, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combiner tous les tags en une seule liste de corpus\n",
    "corpus_tags = [tag for sublist in train_df['split_tags'] for tag in sublist]\n",
    "\n",
    "# Afficher la fréquence de chaque tag dans le corpus\n",
    "value_counts_tags = pd.Series(corpus_tags).value_counts()\n",
    "print(\"Fréquence de chaque tag dans le corpus :\\n\\n\",value_counts_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'java', 'javascript', 'android', 'c#', 'sql', 'spring', 'html', 'jquery', 'aspnet', 'php', 'ios', 'server', 'c++', 'css', 'mvc', 'google', 'linux', 'studio', 'windows', 'web', 'nodejs', 'database', 'mysql', 'django', 'json', 'string', 'file', 'visual', 'iphone', 'objective', 'arrays', 'ruby', 'http', 'laravel', 'angular', 'apache', 'image', 'data', 'reactjs', 'testing', 'pandas', 'selenium', 'api', 'bootstrap', 'amazon', 'git', 'boot', 'services', 'rails', 'maven', 'swift', 'xcode', 'on', 'hibernate', 'jpa', 'react', 'twitter', 'ajax', 'eclipse', 'angularjs', 'bash', 'postgresql', 'framework', 'docker', 'rest', 'typescript', 'chrome', 'ubuntu', 'dataframe', 'xml', 'numpy', 'macos', 'shell', 'ssl', 'datetime', 'spark', 'date', 'unit', 'oracle', 'gradle', 'command', 'excel', 'list', 'security', 'cocoa', 'core', 'forms', 'entity', 'webdriver', 'code', 'performance', 'memory', 'ui', 'class', 'flutter', 'layout', 'variables', 'line', 't', 'learning', 'interface', 'function', 'authentication', 'touch', 'npm', 'unix', 'design', 'wpf', 'matplotlib', 'multithreading', 'azure', 'r', 'machine', 'text', 'user', 'validation', 'time', 'firebase', 'gcc', 'post', 'encoding', 'swing', 'events', 'plugin', 'express', 'cloud', 'processing', 'mobile', 'browser', 'url', 'algorithm', 'object', 'tomcat', 'explorer', 'mongodb', 'parsing', 'dom', 'internet', 'button', 'maps', 'csv', 'native', 'video', 'regex', 'dictionary', 'app', 'iis', 'type', 'webpack', 'build', 'certificate', 'pdf', 'key', 'input', 'exception', 'linq', 'debugging', 'cross', 'facebook', 'io', 'material', 'pip', 'vuejs', 'jdbc', 'opencv', 'select', 'utf', 'to', 'loops', 'ssh', 'upload', 'logging', 'path', 'library', 'orm', 'by', 'table', 'junit', 'error', 'dart', 'network', 'background', 'c++11', 'github', 'email', 'join', 'qt', 'loop', 'static', 'jsp', 'flask', 'formatting', 'asynchronous', 'types', 'import', 'wordpress', 'sorting', 'view', 'jakarta', 'session', 'directory', 'https', 'dynamic', 'ee', 'installation', 'firefox', 'servlets', 'lambda', 'redux', 'aws', 'winforms', 'batch', 'math', 'statement', 'for', 'terminal', 'jenkins', 'stored', 'optimization', 'binding', 'ecmascript', 'pointers', 'connection', 'unicode', 'procedures', 'parameters', 'ipad', 'sockets', 'kotlin', 'compiler', 'xaml', 'module', 'tensorflow', 'permissions', 'group', 'access', 'serialization', 'templates', 'conversion', 'sdk', 'plot', 'intellij', 'search', 'integer', 'oop', 'networking', 'pyspark', 'razor', 'oauth', 'curl', 'nginx', 'proxy', 'colors', 'router', 'canvas', 'character', 'indexing', 'vue', 'model', 'array', 'scikit', 'idea', 'safari', 'cmd', 'client', 'vba', 's3', 'jupyter', 'powershell', 'compose', 'mocking', 'point', 'neural', 'jackson', 'cors', 'iframe', 'sqlite', 'collections', 'package', 'deep', 'learn', 'syntax', 'environment', 'x86', 'null', 'configuration', 'control', 'push', 'cookies', 'dependency', 'methods', 'format', 'management', 'assembly', 'header', 'query', 'programming', 'keras', 'animation', 'inheritance', 'scipy', 'injection', 'annotations', 'system', 'functions', 'async', 'jsf', 'platform', 'uitableview', 'graph', 'bit', 'process', 'stream', 'encryption', 'kubernetes', 'streaming', 'await', 'properties', 'reference', 'request', 'language', 'replace', 'scroll', 'console', 'dialog', 'handling', 'get', 'return', 'audio', 'jar', 'plugins', 'javafx', 'headers', 'engine', 'filter', 'version', 'config', 'if', 'anaconda', 'controller', 'grid', 'status', 'service', 'scripting', 'menu', 'merge', 'cli', 'hash', 'jersey', 'matrix', 'copy', 'tree', 'listview', 'models', 'mockito', 'promise', 'uiview', 'storage', 'cpu', 'timezone', 'floating', 'casting', 'jestjs', 'caching', 'scala', 'binary', 'vector', 'kernel', 'timestamp', 'constructor', 'value', 'drop', 'size', 'architecture', 'deployment', 'insert', 'cordova', 'virtual', 'wcf', 'sqlalchemy', 'linker', 'openssl', 'dependencies', 'chromedriver', 'jax', 'stl', 'initialization', 'files', 'base64', 'plsql', 'codeigniter', 'ec2', 'keyboard', 'youtube', 'hadoop', 'multidimensional', 'swagger', 'scope', 'vbnet', 'html5', 'datepicker', 'applications', 'fragments', 'download', 'computer', 'redirect', 'structures', 'event', 'dockerfile', 'alignment', 'warnings', 'int', 'ng', 'errors', 'mongoose', 'woocommerce', 'store', 'comparison', 'operator', 'buildgradle', 'cmake', 'node', 'angular2', 'fonts', 'arguments', 'winapi', 'export', 'jasmine', 'centos', 'install', 'eloquent', 'enums', 'onclick', 'concurrency', 'arraylist', 'activity', 'keys', 'position', 'identity', 'netbeans', 'osx', 'intent', 'tkinter', 'many', 'integration', 'gitlab', 'count', 'ms', 'content', 'svg', 'ios7', 'seaborn', 'foreach', 'shared', 'components', 'graphics', 'libraries', 'automation', 'token', 'custom', 'soap', 'stack', 'char', 'window', 'axios', 'first', 'camera', 'set', 'sed', 'transactions', 'notebook', 'application', 'pytorch', 'extension', 'symfony', 'scraping', 'vuejs2', 'mvvm', 'include', 'bluetooth', 'numbers', 'nextjs', 'click', 'uikit', 'blob', 'modal', 'navigation', 'embedded', 'conditional', 'tcp', 'notifications', 'concatenation', 'boolean', 'compilation', 'websocket', 'component', 'checkbox', 'boost', 'runtime']\n"
     ]
    }
   ],
   "source": [
    "vocabulary_tags = list(value_counts_tags.head(500).index)\n",
    "print(vocabulary_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons garder dans la colonne `train_df['split_tags']` uniquement les tags les plus fréquents présents dans `vocabulary_tags`. Pour ce faire, nous appliquons la fonction filter_tags à cette colonne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour filtrer les tags\n",
    "def filter_tags(tags):\n",
    "    return [tag for tag in tags if tag in vocabulary_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la fonction sur la colonne 'split_tags'\n",
    "train_df['split_tags'] = train_df['split_tags'].apply(filter_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérifions les valeurs manquantes après avoir filtré les tags :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.taux_de_Remplissage_tableau(train_df, affichage_all = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc pas de valeurs manquantes, nous pouvons continuer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>combined_title_body</th>\n",
       "      <th>split_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19245853</td>\n",
       "      <td>xcode iphone simulator look iphone</td>\n",
       "      <td>question device appearance iphone simulator xc...</td>\n",
       "      <td>xcode iphone simulator look iphone question de...</td>\n",
       "      <td>[ios, iphone, xcode, ios]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55921515</td>\n",
       "      <td>building dockerfile aptget update jailing proc...</td>\n",
       "      <td>docker host ubuntu docker snap dockerfile comm...</td>\n",
       "      <td>building dockerfile aptget update jailing proc...</td>\n",
       "      <td>[docker, ubuntu, nginx, dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72575793</td>\n",
       "      <td>aadsts9002326 crossorigin token redemption isi...</td>\n",
       "      <td>send cross origin request access token react s...</td>\n",
       "      <td>aadsts9002326 crossorigin token redemption isi...</td>\n",
       "      <td>[javascript, reactjs, webpack, axios]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11489824</td>\n",
       "      <td>choose tesseract opencv</td>\n",
       "      <td>tesseract opencv look tesseract ocr engine ope...</td>\n",
       "      <td>choose tesseract opencv tesseract opencv look ...</td>\n",
       "      <td>[python, opencv, computer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3489041</td>\n",
       "      <td>mysqlerror key max key length byte</td>\n",
       "      <td>cause database</td>\n",
       "      <td>mysqlerror key max key length byte cause database</td>\n",
       "      <td>[mysql, sql, ruby, on, rails, indexing, mysql,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                      cleaned_title  \\\n",
       "0  19245853                 xcode iphone simulator look iphone   \n",
       "1  55921515  building dockerfile aptget update jailing proc...   \n",
       "2  72575793  aadsts9002326 crossorigin token redemption isi...   \n",
       "3  11489824                            choose tesseract opencv   \n",
       "4   3489041                 mysqlerror key max key length byte   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  question device appearance iphone simulator xc...   \n",
       "1  docker host ubuntu docker snap dockerfile comm...   \n",
       "2  send cross origin request access token react s...   \n",
       "3  tesseract opencv look tesseract ocr engine ope...   \n",
       "4                                     cause database   \n",
       "\n",
       "                                 combined_title_body  \\\n",
       "0  xcode iphone simulator look iphone question de...   \n",
       "1  building dockerfile aptget update jailing proc...   \n",
       "2  aadsts9002326 crossorigin token redemption isi...   \n",
       "3  choose tesseract opencv tesseract opencv look ...   \n",
       "4  mysqlerror key max key length byte cause database   \n",
       "\n",
       "                                          split_tags  \n",
       "0                          [ios, iphone, xcode, ios]  \n",
       "1                [docker, ubuntu, nginx, dockerfile]  \n",
       "2              [javascript, reactjs, webpack, axios]  \n",
       "3                         [python, opencv, computer]  \n",
       "4  [mysql, sql, ruby, on, rails, indexing, mysql,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons que la taille des listes de la colonne split_tags a changé puisque nous n'avons gardé que les mots fréquents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer les listes de tags en une matrice binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour préparer les données pour l'entraînement des modèles supervisés, nous devons encoder les tags sous une forme binaire. Pour ce faire, nous utilisons MultiLabelBinarizer de scikit-learn, qui permet de transformer les listes de tags en une matrice binaire. Chaque colonne de cette matrice représente un tag, et chaque ligne indique la présence ou l'absence des tags pour un document donné:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser l'encodeur MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Appliquer l'encodeur sur la colonne 'split_tags' du DataFrame train_df\n",
    "# Cela transforme les listes de tags en une matrice binaire\n",
    "y = mlb.fit_transform(train_df['split_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['access' 'activity' 'ajax' 'algorithm' 'alignment' 'amazon' 'anaconda'\n",
      " 'android' 'angular' 'angular2']\n",
      "Transformed Data:\n",
      " [[0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Affichage des classes identifiées par le MultiLabelBinarizer\n",
    "print(\"Classes:\", mlb.classes_[:10])\n",
    "\n",
    "# Affichage de la matrice des étiquettes transformées\n",
    "print(\"Transformed Data:\\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvgarde de l'encodeur MultiLabelBinarizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(mlb, 'Model/supervised/mlb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trier les mots par fréquence et sélectionner les 500 plus fréquents dans le corpus `df['combined_title_body']`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fréquence de chaque mot dans le corpus des corps de texte nettoyés :\n",
      " file             19114\n",
      "error            17715\n",
      "code             17381\n",
      "use              14901\n",
      "data              8756\n",
      "                 ...  \n",
      "entought             1\n",
      "popperminjs          1\n",
      "oraconnection        1\n",
      "cwe                  1\n",
      "amplayer             1\n",
      "Length: 64654, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combiner tout le contenu des corps de texte nettoyés en une seule chaîne de texte\n",
    "corpus_combined_title_body = \" \".join(train_df['combined_title_body'].values).lower()\n",
    "\n",
    "# Afficher la fréquence de chaque mot dans le corpus des corps de texte nettoyés\n",
    "corpus_combined_title_body_tokens = corpus_combined_title_body.split()\n",
    "value_counts_combined_title_body = pd.Series(corpus_combined_title_body_tokens).value_counts()\n",
    "print(\"Fréquence de chaque mot dans le corpus des corps de texte nettoyés :\\n\", value_counts_combined_title_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 500 mots les plus fréquents du corpus des corps de texte nettoyés :\n",
      " ['file', 'error', 'code', 'use', 'data', 'value', 'server', 'function', 'method', 'class', 'user', 'set', 'application', 'image', 'object', 'time', 'string', 'project', 'help', 'app', 'page', 'python', 'change', 'table', 'question', 'line', 'test', 'window', 'type', 'found', 'command', 'database', 'request', 'java', 'array', 'thanks', 'version', 'column', 'list', 'solution', 'issue', 'result', 'button', 'try', 'text', 'look', 'return', 'android', 'view', 'update', 'web', 'message', 'query', 'read', 'number', 'script', 'element', 'html', 'spring', 'output', 'library', 'sql', 'api', 'access', 'json', 'simple', 'edit', 'idea', 'form', 'key', 'case', 'javascript', 'build', 'service', 'field', 'right', 'row', 'thing', 'post', 'client', 'property', 'url', 'input', 'date', 'option', 'browser', 'exception', 'jquery', 'install', 'php', 'convert', 'link', 'check', 'controller', 'parameter', 'answer', 'default', 'content', 'program', 'click', 'load', 'folder', 'understand', 'point', 'difference', 'path', 'write', 'think', 'multiple', 'model', 'start', 'display', 'format', 'c', 'size', 'package', 'http', 'module', '#', 'connection', 'directory', 'correct', 'io', 'google', 'event', 'header', 'studio', 'system', 'component', 'fix', 'log', 'chrome', 'custom', 'response', 'process', 'mean', 'send', 'character', 'source', 'order', 'cs', 'select', 'c++', 'item', 'color', 'ie', 'mysql', 'etc', 'reference', 'information', 'instance', 'pas', 'device', 'contains', 'lot', 'loop', 'background', 'd', 'attribute', 'website', 'thread', 'statement', 'note', 'figure', 'configuration', 'implement', 'bit', 'entity', 'support', 'end', 'import', 'dependency', 'store', 'eclipse', 'tag', 'reason', 'connect', 'site', 'xml', 'linux', 'documentation', 'certificate', 'tell', 'machine', 'console', 'v', 'memory', 'screen', 'solve', 'framework', 'eg', 'ajax', 'environment', 'aspnet', 'video', 'variable', 'dataframe', 'resource', 'password', 'search', 'control', 'advance', 'null', 'map', 'rest', 'nt', 'print', 'index', 'xcode', 'token', 'tool', 'step', 'mvc', 'bar', 'thank', 'bootstrap', 'approach', 'argument', 'container', 'task', 'angular', 'address', 'insert', 'box', 'react', 'achieve', 'suggestion', 'thought', 'handle', 'panda', 'm', 'record', 'generate', 'cell', 'execute', 'place', 'interface', 'action', 'div', 'boot', 'node', 'structure', 'login', 'repository', 'template', 'location', 'copy', 'feature', 'space', 'state', 'email', 'port', 'django', 'tutorial', 'authentication', 'reading', 'include', 'standard', 'download', 'stack', 'implementation', 'docker', 'j', 'sample', 'session', 'db', 'compile', 'pdf', 'day', 'permission', 'procedure', 'upload', 'ubuntu', 'plugin', 'cause', 'syntax', 'setup', 'fails', 'jar', 'byte', 'laravel', 'document', 'operation', 'group', 'tomcat', 'nodejs', 'git', 'label', 'scroll', 'hibernate', 'width', 'kind', 'sort', '_', 'filter', 'tab', 'context', 'throw', 'mac', 'iphone', 'network', 'setting', 'height', 'performance', 'firefox', 'layout', 'oracle', 'ok', 'language', 'excel', 'delete', 'resolve', 'checked', 'c#', 'debug', 'mode', 'happens', 'word', 'left', 'detail', 'integer', 'o', 'plot', 'provide', 'match', 'swift', 'validation', 'csv', 'core', 'explain', 'parent', 'apache', 'unit', 'style', 'run', 'binary', 'annotation', 'level', 'terminal', 'config', 'root', 'developer', 'security', 'stream', 'remote', 'child', 'block', 'create', 'jpa', 'mobile', 'net', 'menu', 'frame', 'selenium', 'gradle', 'info', 'status', 'npm', 'host', 'compiler', 'position', 'exist', 'pointer', 'ssl', 'enter', 'ui', 'icon', 'people', 'font', 'building', 'comment', 'internet', 'activity', 'extension', 'attempt', 'avoid', 'specify', 'receive', 'route', 'entry', 'computer', 'job', 'development', 'constructor', 'section', 'bean', 'shell', 'account', 'second', 'guess', 'count', 'trouble', 'body', 'course', 'exists', 'duplicate', 'push', 'algorithm', 'dialog', 'expression', 'proxy', 'target', 'github', 'driver', 'schema', 'parse', 'contain', 'bash', 'displayed', 'way', 'domain', 'play', 'product', 'join', 'present', 'matter', 'mock', 'rail', 'perform', 'title', 'doc', 'report', 'stop', 'submit', 'int', 'behavior', 'condition', 'ip', 'purpose', 'configure', 'effect', 'functionality', 'public', 'cache', 'detect', 'success', 'proper', 'passing', 'utf8', 'pattern', 'postgresql', 'article', 'navigation', 'gcc', 'sdk', 'extract', 'collection', 'retrieve', 'hour', 'trigger', 'numpy', 'picture', 'batch', 'sent', 'built', 'datetime', 'modal', 'safari', 'iframe', 'runtime', 'notification', 'define', 'situation', 'turn', 'length', 'definition', 'flutter', 'fragment', 'snippet', 'unique', 'member', 'range', 'transaction', 'matrix', 'practice', 'equivalent', 'anybody', 'stuff', 'constraint', 'switch', 'vector', 'export', 'suggest', 'execution', 'stuck', 'instruction', 'apps', 'appreciate', 'socket', 'render', 'fetch', 'profile', 'ii', 'break', 'ssh', 'graph', 'alternative', 'installation', 'online', 'keyboard']\n"
     ]
    }
   ],
   "source": [
    "# Créer la liste du vocabulaire des mots les plus fréquents du corpus\n",
    "vocabulary = list(value_counts_combined_title_body.head(500).index)\n",
    "print(\"Les 500 mots les plus fréquents du corpus des corps de texte nettoyés :\\n\", vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file', 'error', 'code', 'use', 'data']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectoriser les textes de la colonne `train_df['combined_title_body']`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser TfidfVectorizer pour vectoriser les textes des questions en utilisant le vocabulaire filtré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_supervised = TfidfVectorizer(vocabulary=vocabulary)\n",
    "X_tfidf = vectorizer_supervised.fit_transform(train_df['combined_title_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39881x500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 512562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvgarde du vectorizer_supervised au format pkl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(vectorizer_supervised, 'Model/supervised/vectorizer_supervised.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diviser les données en ensembles d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer les performances de nos modèles supervisés, on doit diviser nos données en ensembles d'entraînement et de test. on va utiliser la fonction train_test_split de scikit-learn pour effectuer cette division de manière aléatoire, tout en réservant 20% des données pour les tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour l'entraînement, le calcul de la performance et l'enregistrement des modèles :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer les performances des modèles de classification multi-étiquette, on calcule le score de Jaccard moyen et on évalue les modèles après leur entraînement. Le fichier `init.py` contient deux fonctions : `jaccard` pour le calcul du score de Jaccard et `train_and_evaluate` pour l'entraînement et l'évaluation des modèles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On initialise ces deux dictionnaires pour stocker les performances des modèles et les modèles entraînés : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performance = {}\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression - F1 Score: 0.41600491586311217\n",
      "Logistic Regression - Jaccard Score: 0.634172341639209\n",
      "CPU times: total: 9.23 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"Logistic Regression\"\n",
    "model = OneVsRestClassifier(LogisticRegression(max_iter=500), n_jobs=-1)\n",
    "\n",
    "with parallel_backend(\"threading\"):\n",
    "    trained_models[model_name] = func.train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, models_performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement de SGD Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD Classifier...\n",
      "SGD Classifier - F1 Score: 0.4040752808442348\n",
      "SGD Classifier - Jaccard Score: 0.630577407052224\n",
      "CPU times: total: 6.86 s\n",
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"SGD Classifier\"\n",
    "model = OneVsRestClassifier(SGDClassifier(max_iter=500), n_jobs=-1)\n",
    "\n",
    "with parallel_backend(\"threading\"):\n",
    "    trained_models[model_name] = func.train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement de Support Vector Machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Support Vector Machine...\n",
      "Support Vector Machine - F1 Score: 0.4472683976736731\n",
      "Support Vector Machine - Jaccard Score: 0.647617940956451\n",
      "CPU times: total: 47.9 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"Support Vector Machine\"\n",
    "model = OneVsRestClassifier(LinearSVC(max_iter=500), n_jobs=-1)\n",
    "with parallel_backend(\"threading\"):\n",
    "    trained_models[model_name] = func.train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement de XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "XGBoost - F1 Score: 0.46803085357302227\n",
      "XGBoost - Jaccard Score: 0.6559013773332233\n",
      "CPU times: total: 10h 59min 31s\n",
      "Wall time: 53min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"XGBoost\"\n",
    "# Mise à jour du modèle avec les meilleurs paramètres trouvés\n",
    "model = OneVsRestClassifier(XGBClassifier(n_estimators=500, use_label_encoder=False, eval_metric='logloss'))\n",
    "with parallel_backend(\"threading\"):\n",
    "    trained_models[model_name] = func.train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement de Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Random Forest - F1 Score: 0.3787706739076771\n",
      "Random Forest - Jaccard Score: 0.620371427874497\n",
      "CPU times: total: 18min 59s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"Random Forest\"\n",
    "model = OneVsRestClassifier(RandomForestClassifier(n_estimators=20), n_jobs=-1)\n",
    "with parallel_backend(\"threading\"):\n",
    "    trained_models[model_name] = func.train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement de LightGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM...\n",
      "LightGBM - F1 Score: 0.4556589906908378\n",
      "LightGBM - Jaccard Score: 0.650881801750326\n",
      "CPU times: total: 5h 6min 56s\n",
      "Wall time: 25min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"LightGBM\"\n",
    "model = OneVsRestClassifier(LGBMClassifier(n_estimators=500))\n",
    "with parallel_backend(\"threading\"):\n",
    "    trained_models[model_name] = func.train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement de AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AdaBoost...\n",
      "AdaBoost - F1 Score: 0.4311279826464208\n",
      "AdaBoost - Jaccard Score: 0.6364123426787159\n",
      "CPU times: total: 10min 4s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"AdaBoost\"\n",
    "model = OneVsRestClassifier(AdaBoostClassifier(n_estimators=20))\n",
    "with parallel_backend(\"threading\"):\n",
    "    trained_models[model_name] = func.train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertir les résultats en DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Jaccard Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.416005</td>\n",
       "      <td>0.634172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD Classifier</th>\n",
       "      <td>0.404075</td>\n",
       "      <td>0.630577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.447268</td>\n",
       "      <td>0.647618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.468031</td>\n",
       "      <td>0.655901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.378771</td>\n",
       "      <td>0.620371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.455659</td>\n",
       "      <td>0.650882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.431128</td>\n",
       "      <td>0.636412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 Score  Jaccard Score\n",
       "Logistic Regression     0.416005       0.634172\n",
       "SGD Classifier          0.404075       0.630577\n",
       "Support Vector Machine  0.447268       0.647618\n",
       "XGBoost                 0.468031       0.655901\n",
       "Random Forest           0.378771       0.620371\n",
       "LightGBM                0.455659       0.650882\n",
       "AdaBoost                0.431128       0.636412"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_dict(models_performance, orient=\"index\")\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection du meilleur modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour identifier le meilleur modèle parmi ceux que l'on a entraînés, on compare les scores moyens de Jaccard de chaque modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: XGBoost, Jaccard Score: 0.6559013773332233\n"
     ]
    }
   ],
   "source": [
    "# Initialiser les variables pour suivre le meilleur modèle et son score de Jaccard\n",
    "best_model = None\n",
    "best_jaccard = 0\n",
    "best_model_name = None\n",
    "\n",
    "# Parcourir tous les modèles entraînés et leurs scores de Jaccard\n",
    "for model_name, (trained_model, jaccard_avg) in trained_models.items():\n",
    "    # Si le score de Jaccard actuel est meilleur que le meilleur score enregistré\n",
    "    if jaccard_avg > best_jaccard:\n",
    "        # Mettre à jour le meilleur score de Jaccard\n",
    "        best_jaccard = jaccard_avg\n",
    "        # Mettre à jour le meilleur modèle\n",
    "        best_model = trained_model\n",
    "        # Mettre à jour le nom du meilleur modèle\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Afficher le meilleur modèle et son score de Jaccard\n",
    "print(f'Best Model: {best_model_name}, Jaccard Score: {best_jaccard}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_path = 'Model/supervised/best_model.pkl'\n",
    "# dump(best_model, best_model_path)\n",
    "# print('Best model saved to %s', best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tester le meilleur modèle pour la prédiction des tags avant de l'implémenter dans la future API :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait le test avec un seul exemple de la fonction predict_tags :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = train_df['combined_title_body'][4]  # Utiliser le quatrième texte du DataFrame train_df comme exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Tags: ['python', 'c#', 'key', 'sql', 'database']\n"
     ]
    }
   ],
   "source": [
    "# Exemple de prédiction pour un nouveau texte\n",
    "predicted_tags = func.predict_tags(new_text, best_model, vectorizer_supervised, mlb)  # Prédire les tags pour le nouveau texte\n",
    "print(\"Predicted Tags:\", predicted_tags)  # Afficher les tags prédits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédire les tags pour toutes les questions de test_df :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour améliorer l'efficacité de la prédiction des tags sur un grand nombre de textes, on peut utiliser la parallélisation. La fonction `parallel_predict_tags` de la bibliothèque `joblib` permet d'exploiter les capacités multicœur de la machine, réduisant ainsi le temps nécessaire pour traiter toutes les questions de `test_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12h 14min 8s\n",
      "Wall time: 1h 22min 15s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>combined_title_body</th>\n",
       "      <th>split_tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32177764</td>\n",
       "      <td>weight_decay meta parameter caffe</td>\n",
       "      <td>bvlccaffe git training meta parameter meta par...</td>\n",
       "      <td>weight_decay meta parameter caffe bvlccaffe gi...</td>\n",
       "      <td>[machine, learning, neural, network, deep, lea...</td>\n",
       "      <td>[validation, control, jdbc, parameters, git]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35870760</td>\n",
       "      <td>pyspark dataframe sqllike clause</td>\n",
       "      <td>filter pyspark dataframe sqllike clause tuple ...</td>\n",
       "      <td>pyspark dataframe sqllike clause filter pyspar...</td>\n",
       "      <td>[python, sql, apache, spark, dataframe, pyspark]</td>\n",
       "      <td>[dataframe, apache, python, pyspark, spark]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10679214</td>\n",
       "      <td>set contenttype header httpclient request</td>\n",
       "      <td>set header object api allows header try throw ...</td>\n",
       "      <td>set contenttype header httpclient request set ...</td>\n",
       "      <td>[c#, aspnet, rest, content, type, dotnet, http...</td>\n",
       "      <td>[javascript, api, c#, http, java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22157596</td>\n",
       "      <td>aspnet web api operationcanceledexception brow...</td>\n",
       "      <td>user load page ajax request hit aspnet web api...</td>\n",
       "      <td>aspnet web api operationcanceledexception brow...</td>\n",
       "      <td>[aspnet, iis, aspnet, web, api, task, parallel...</td>\n",
       "      <td>[c#, mvc, web, ajax, aspnet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6100573</td>\n",
       "      <td>draw line object</td>\n",
       "      <td>line control window form draw line line</td>\n",
       "      <td>draw line object line control window form draw...</td>\n",
       "      <td>[c#, winforms, user, interface, drawing, 2d]</td>\n",
       "      <td>[insert, xaml, binding, c#, winforms]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                      cleaned_title  \\\n",
       "0  32177764                  weight_decay meta parameter caffe   \n",
       "1  35870760                   pyspark dataframe sqllike clause   \n",
       "2  10679214          set contenttype header httpclient request   \n",
       "3  22157596  aspnet web api operationcanceledexception brow...   \n",
       "4   6100573                                   draw line object   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  bvlccaffe git training meta parameter meta par...   \n",
       "1  filter pyspark dataframe sqllike clause tuple ...   \n",
       "2  set header object api allows header try throw ...   \n",
       "3  user load page ajax request hit aspnet web api...   \n",
       "4            line control window form draw line line   \n",
       "\n",
       "                                 combined_title_body  \\\n",
       "0  weight_decay meta parameter caffe bvlccaffe gi...   \n",
       "1  pyspark dataframe sqllike clause filter pyspar...   \n",
       "2  set contenttype header httpclient request set ...   \n",
       "3  aspnet web api operationcanceledexception brow...   \n",
       "4  draw line object line control window form draw...   \n",
       "\n",
       "                                          split_tags  \\\n",
       "0  [machine, learning, neural, network, deep, lea...   \n",
       "1   [python, sql, apache, spark, dataframe, pyspark]   \n",
       "2  [c#, aspnet, rest, content, type, dotnet, http...   \n",
       "3  [aspnet, iis, aspnet, web, api, task, parallel...   \n",
       "4       [c#, winforms, user, interface, drawing, 2d]   \n",
       "\n",
       "                                 predicted_tags  \n",
       "0  [validation, control, jdbc, parameters, git]  \n",
       "1   [dataframe, apache, python, pyspark, spark]  \n",
       "2             [javascript, api, c#, http, java]  \n",
       "3                  [c#, mvc, web, ajax, aspnet]  \n",
       "4         [insert, xaml, binding, c#, winforms]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Paralléliser l'application de la fonction predict_tags\n",
    "def parallel_predict_tags(df, model, vectorizer, mlb, n_jobs=-1):\n",
    "    df['predicted_tags'] = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(func.predict_tags)(text, model, vectorizer, mlb) for text in df['combined_title_body']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Appliquer la fonction parallélisée\n",
    "with parallel_backend(\"threading\"):\n",
    "    test_df = parallel_predict_tags(test_df, best_model, vectorizer_supervised, mlb)\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde de `test_df` avec `predicted_tags` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"data/stack_overflow_data_cleaned_test_predicted_tags_supervised.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculer le taux de couverture moyen pour les tags prédits par le modèle supervisé:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer la qualité des prédictions, on calcule le taux de couverture moyen des tags prédits. Cette métrique mesure la proportion de tags corrects prédits par rapport aux tags réels en utilisant la fonction `coverage_rate` sur `test_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de couverture moyen pour le modèle supervisé: 0.37\n"
     ]
    }
   ],
   "source": [
    "# Calculer le taux de couverture moyen pour les tags prédits par le modèle supervisé\n",
    "average_coverage_supervised = func.coverage_rate(test_df, 'split_tags', 'predicted_tags')\n",
    "print(f\"Taux de couverture moyen pour le modèle supervisé: {average_coverage_supervised:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40096abdad38073fd0adf65764f8ebf74e8a1cb9bfd1094a6a882613854709a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
